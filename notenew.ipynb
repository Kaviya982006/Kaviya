{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b2061",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1]: Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "# Ensure output directories for the web app\n",
    "os.makedirs(\"web/static\", exist_ok=True)\n",
    "# In [2]: Load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Nandh\\OneDrive\\Documents\\project\\train.csv\")\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [3]: Inspect dataset\n",
    "df.info()\n",
    "df.describe()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [4]: Check class distribution and missing values\n",
    "print(df[\"Fake\"].value_counts())\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [5]: Visualize class imbalance\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x=\"Fake Or Not Category\", data=df, palette=\"cool\")\n",
    "plt.title(\"Class Label Counts\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [6]: Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "df.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [7]: Balance the dataset (upsample minority, downsample majority)\n",
    "df_majority = df[df['Fake Or Not Category'] == 1]\n",
    "df_minority = df[df['Fake Or Not Category'] == 0]\n",
    "\n",
    "n_target = min(len(df_majority), len(df_minority))\n",
    "if n_target < 300:\n",
    "    n_target = 500  # fallback target\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, replace=True, n_samples=n_target, random_state=123)\n",
    "df_majority_downsampled = resample(df_majority, replace=False, n_samples=n_target, random_state=123)\n",
    "\n",
    "df_balanced = pd.concat([df_minority_upsampled, df_majority_downsampled]).sample(frac=1, random_state=123)\n",
    "df_balanced['Fake Or Not Category'].value_counts()\n",
    "\n",
    "\n",
    "\n",
    "# In [8]: Visualize balanced data\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.countplot(x=\"Fake Or Not Category\", data=df_balanced, palette=\"cubehelix\")\n",
    "plt.title(\"Balanced Class Counts\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [9]: Drop unused columns (adjust to your dataset)\n",
    "df = df_balanced.copy()\n",
    "for col in [\"UserID\", \"profile pic\"]:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(columns=[col])\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "# In [10]: Split features and target\n",
    "X = df.drop(columns=['Fake Or Not Category'])\n",
    "y = df['Fake Or Not Category']\n",
    "X.shape, y.shape\n",
    "\n",
    "\n",
    "\n",
    "# In [11]: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=40\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [12]: Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save test features for any external check if needed\n",
    "pd.DataFrame(X_test).to_csv(\"web/static/test_features_preview.csv\", index=False)\n",
    "\n",
    "# Persist scaler for the web app\n",
    "pickle.dump(scaler, open(\"web/scaler.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [13]: KNN\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "pred_knn = knn_model.predict(X_test)\n",
    "train_accuracy = accuracy_score(y_train, knn_model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, pred_knn)\n",
    "\n",
    "pickle.dump(knn_model, open(\"web/knn_model.pkl\", \"wb\"))\n",
    "print(\"KNN Train:\", train_accuracy, \"Test:\", test_accuracy)\n",
    "print(classification_report(y_test, pred_knn))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [14]: Confusion matrix KNN\n",
    "cm_knn = confusion_matrix(y_test, pred_knn)\n",
    "sns.heatmap(pd.DataFrame(cm_knn, index=[\"Real\",\"Fake\"], columns=[\"Real\",\"Fake\"]), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - KNN\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [15]: Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "log_model.fit(X_train, y_train)\n",
    "pred_log = log_model.predict(X_test)\n",
    "train_accuracy1 = accuracy_score(y_train, log_model.predict(X_train))\n",
    "test_accuracy1 = accuracy_score(y_test, pred_log)\n",
    "\n",
    "pickle.dump(log_model, open(\"web/log_model.pkl\", \"wb\"))\n",
    "print(\"LogReg Train:\", train_accuracy1, \"Test:\", test_accuracy1)\n",
    "print(classification_report(y_test, pred_log))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [16]: Confusion matrix Logistic Regression\n",
    "cm_log = confusion_matrix(y_test, pred_log)\n",
    "sns.heatmap(pd.DataFrame(cm_log, index=[\"Real\",\"Fake\"], columns=[\"Real\",\"Fake\"]), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [17]: Decision Tree (simple tuned defaults; adjust as needed)\n",
    "dt = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=5, random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "pred_dt = dt.predict(X_test)\n",
    "train_accuracy2 = accuracy_score(y_train, dt.predict(X_train))\n",
    "test_accuracy2 = accuracy_score(y_test, pred_dt)\n",
    "\n",
    "pickle.dump(dt, open(\"web/dt_model.pkl\", \"wb\"))\n",
    "print(\"DecisionTree Train:\", train_accuracy2, \"Test:\", test_accuracy2)\n",
    "print(classification_report(y_test, pred_dt))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [18]: Confusion matrix Decision Tree\n",
    "cm_dt = confusion_matrix(y_test, pred_dt)\n",
    "sns.heatmap(pd.DataFrame(cm_dt, index=[\"Real\",\"Fake\"], columns=[\"Real\",\"Fake\"]), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [19]: Random Forest\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=120, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "train_accuracy3 = accuracy_score(y_train, rf.predict(X_train))\n",
    "test_accuracy3 = accuracy_score(y_test, pred_rf)\n",
    "\n",
    "pickle.dump(rf, open(\"web/rf_model.pkl\", \"wb\"))\n",
    "print(\"RandomForest Train:\", train_accuracy3, \"Test:\", test_accuracy3)\n",
    "print(classification_report(y_test, pred_rf))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [20]: Confusion matrix Random Forest\n",
    "cm_rf = confusion_matrix(y_test, pred_rf)\n",
    "sns.heatmap(pd.DataFrame(cm_rf, index=[\"Real\",\"Fake\"], columns=[\"Real\",\"Fake\"]), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Random Forest\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [21]: XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=500, learning_rate=0.05, max_depth=5,\n",
    "    subsample=0.9, colsample_bytree=0.9, random_state=42, n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "pred_xgb = xgb_model.predict(X_test)\n",
    "train_accuracy4 = accuracy_score(y_train, xgb_model.predict(X_train))\n",
    "test_accuracy4 = accuracy_score(y_test, pred_xgb)\n",
    "\n",
    "pickle.dump(xgb_model, open(\"web/xgb_model.pkl\", \"wb\"))\n",
    "print(\"XGBoost Train:\", train_accuracy4, \"Test:\", test_accuracy4)\n",
    "print(classification_report(y_test, pred_xgb))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [22]: Confusion matrix XGBoost\n",
    "cm_xgb = confusion_matrix(y_test, pred_xgb)\n",
    "sns.heatmap(pd.DataFrame(cm_xgb, index=[\"Real\",\"Fake\"], columns=[\"Real\",\"Fake\"]), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - XGBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [30]: Confusion matrices side by side (all models)\n",
    "cms = {\n",
    "    \"KNN\": cm_knn,\n",
    "    \"Logistic Regression\": cm_log,\n",
    "    \"Decision Tree\": cm_dt,\n",
    "    \"Random Forest\": cm_rf,\n",
    "    \"XGBoost\": cm_xgb\n",
    "}\n",
    "class_names = ['Real', 'Fake']\n",
    "fig, axes = plt.subplots(1, 5, figsize=(25,5))\n",
    "for ax, (title, cm) in zip(axes, cms.items()):\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Actual\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"web/static/confusion_matrices.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [31]: Final comparison table\n",
    "all_model_result = pd.DataFrame([\n",
    "    ['KNN-Classifier', train_accuracy, test_accuracy],\n",
    "    ['Logistic regression', train_accuracy1, test_accuracy1],\n",
    "    ['Decision Tree-Classifier', train_accuracy2, test_accuracy2],\n",
    "    ['Random Forest', train_accuracy3, test_accuracy3],\n",
    "    ['XGBoost', train_accuracy4, test_accuracy4]\n",
    "], columns=['Classifier', 'Train-Accuracy', 'Test-Accuracy'])\n",
    "\n",
    "print(all_model_result)\n",
    "all_model_result.to_csv(\"web/static/all_model_result.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In [32]: Bar chart for accuracy comparison and save for web app\n",
    "plt.figure(figsize=(10,6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(all_model_result))\n",
    "plt.bar(index, all_model_result['Train-Accuracy'], bar_width, label='Train Accuracy', color='skyblue')\n",
    "plt.bar(index + bar_width, all_model_result['Test-Accuracy'], bar_width, label='Test Accuracy', color='salmon')\n",
    "\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Classifier Performance')\n",
    "plt.xticks(index + bar_width/2, all_model_result['Classifier'], rotation=30)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"web/static/accuracy_bar.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Save a default chosen model (RandomForest) for web prediction\n",
    "pickle.dump(rf, open(\"web/model_for_web.pkl\", \"wb\"))\n",
    "\n",
    "print(\"Artifacts saved to web/static/: confusion_matrices.png, accuracy_bar.png, all_model_result.csv\")\n",
    "print(\"Models saved to web/: scaler.pkl, model_for_web.pkl (RandomForest)\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save confusion matrix diagram\n",
    "plt.savefig(\"static/confusion_matrix.png\", dpi=150)\n",
    "\n",
    "# Save accuracy bar chart\n",
    "plt.savefig(\"static/accuracy_bar.png\", dpi=150)\n",
    "\n",
    "# Save accuracy results table\n",
    "all_model_result.to_csv(\"static/all_model_result.csv\", index=False)\n",
    "\n",
    "print(\"Files saved: confusion_matrix.png, accuracy_bar.png, all_model_result.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
